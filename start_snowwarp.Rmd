---
title: "Start SnowWarp!"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{start_snowwarp}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

## Intro

Welcome to the snowwarp package! This package was created to provide open-source access to SnowWarp fractional snow covered area (fSCA) data and accompanying annual statistics. SnowWarp is a new data fusion approach to create a daily time-series of 30 m snow cover observations. It was created to meet the data needs of applied researchers, who desire a snow cover dataset with a high enough spatial and temporal resolution to match the scale of their work. The product is derived by leveaging daily MODIS snow cover data, which captures the temporal dynamics of snow cover, and Dynamic Time Warping (DTW), which is used to re-order historical Landsat observations to account for inter-annual variability. For more information on the SnowWarp algorithm and it's methods see [Berman et al. (2018)](https://www.sciencedirect.com/science/article/abs/pii/S0034425718303626). For methods of key annual snow statistics and a novel application of SnowWarp please see [Berman et al. (2019)](https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0215243). 

Please note the following when using SnowWarp:

1. fSCA data from MODIS and Landsat is now used as the input into the SnowWarp algorithm. fSCA is calculated using a linear regression on NDSI following the methods of [Aalstad et al. (2020)](https://www.sciencedirect.com/science/article/pii/S0034425719306388). The regression formula is fSCA = (1.45) * NDSI -0.01. This was not the orginal input data used in Berman et al. (2018) and this data has not been validated! Please use at your own discretion. That being said, the new fSCA approach should help to deal with the systematic underestimation of fSCA that was found in Landsat TMSCAG data.
2. Data is pre-processed in Google Earth Engine (GEE) in WGS84 projection. Output files are GeoTiff (.tif) and ~30 meters resolution.
3. Data is currently available from August 1, 2000 until July 31, 2019. New data will be added at the end of each annual 'winter' year (i.e. late summer).
3. Use of SnowWarp data is free but must be cited. Please cite:
  i) [Berman et al. (2018)](https://www.sciencedirect.com/science/article/abs/pii/S0034425718303626)
  ii) Berman, E.E., Francini, S., Coops, N.C. (2020). snowwarp. R package.

The following instructions should be followed to ensure proper use of the snowwarp package. The general workflow is:

1. Organize and pre-process data on Google Earth Engine.
2. Download pre-processed data.
3. Process SnowWarp daily fSCA.
4. Extract key SnowWarp annual statistics.

## 1. Organize and pre-process data on Google Earth Engine

1. Create and/or sign-in to your Google Earth Engine Account
2. [Open the SnowWarpPackage API by following this link](https://code.earthengine.google.com/?accept_repo=users/sfrancini/SnowWarpPackage). Opening the link will create a script on your GEE account that can be used to pre-process data. The script will appear in a "Reader" repository in your "Scripts" panel.
3.  Click on the "SnowWarp-API" script and click "Run". This should open the SnowWarp API and allow you to specify a shapefile (study area) and Google Drive output folder.
4. Follow the instructions to upload a shapefile of your study area and download the data to Google Drive. Please note that a free account only has 15 GB of space on Google Drive. If your study area is too large (i.e. when you try to pre-process the data on GEE you get an error), try cutting the area into smaller parts and running separately. Once you download the imagery to your hard drive, you can delete the data from Google Drive and run the next study area chunk.

## 2. Download pre-processed data

Once the data is pre-processed on GEE and located on your Google Drive account, the rest of the process takes place in R. Use the download_snowwarp_data function (run "?download_snowwarp_data" for details) to download the pre-processed imagery to a local hard drive. The folder where you save the imagery will be the "folder" variable for the rest of the snowwarp functions.

## 3. Process SnowWarp daily fSCA

This is main part of the SnowWarp algorithm and also the most time consuming. Depending on your processing power, read/write speed, and allocation of cpus for parallel processing, this function can run from anywhere from a few days to a couple weeks. Before getting started, run the get_snowwarp_tiles function (run "?get_snowwarp_tiles" for details) function, which will return the number of Landsat tiles you need to process. When you run the process_snowwarp function (run "process_snowwarp" for details), you can specify the tile numbers you want to process in each iteration. It is always better to process all the years of data you want at the same time, so if you have space or processing constraints, start by restricting the number of tiles processed in each iteration. SnowWarp outputs daily fSCA and each raster contains 365 bands corresponding to August 1 - July 31. For example, if you run years = c(2000, 2004), you will get two rasters with data from August 1, 2000 - July 31, 2001 and August 1, 2004 - July 31, 2005. Leap years are not accounted for (365 days every year). The output will be located inside "folder/output", where "folder" is the directory with the pre-processed imagery from GEE.

## 4. Extract key annual statistics

The SnowWarp dataset contains daily values at ~30 m spatial resolution -- This is a LOT of data!!! For many applications, users may only be interested in annual statistics that characterize snow dynamics. The extract_snowwarp_stats function (run "?extract_snowwarp_stats" for details) processes three key statistics and outputs them into an additional raster file (one per winter year) in the "output" folder with 3 bands. The 3 bands are:

1. Date of snow accumulation
2. Date of snow melt
3. Number of days with snow cover in year

Many other statistics can be calculated from SnowWarp, but these should get you started!

## That's it!

Thanks for your interest in these data! We are very excited to share SnowWarp with the research community and make it available to data users for many applications. This is a new package and deals with a large amount of data and processing, and we would definitely appreciate your feedback about it's usability and functionality. There is lots of room for this code to be optimized for easier use and faster processing of large areas, and we look forward to adding on to it in the future. Any effort to help improve functionality is welcome!

Best of luck,

Ethan Berman, Saverio Francini, and Nicholas Coops. 2020.


